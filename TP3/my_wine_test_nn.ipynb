{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp39-cp39-win_amd64.whl (430.8 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-win_amd64.whl (13.1 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.13.3-cp39-cp39-win_amd64.whl (34 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.21.4+vanilla)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.42.0-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp39-cp39-win_amd64.whl (2.8 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (56.0.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\j-mla\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=ebac43c95c72e9245c5f74b70ef964c471dc0b41f5b740383e88791fd5890dd5\n",
      "  Stored in directory: c:\\users\\j-mla\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.42.0 h5py-3.6.0 importlib-metadata-4.8.2 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0 termcolor-1.1.0 typing-extensions-4.0.0 wrapt-1.13.3 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    1998\n",
      "5    1500\n",
      "7     739\n",
      "4     154\n",
      "8     133\n",
      "3      21\n",
      "9       2\n",
      "Name: quality, dtype: int64\n",
      "4547\n",
      "(4547, 13)\n",
      "(4547,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>color_red</th>\n",
       "      <th>color_white</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.092</td>\n",
       "      <td>40.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.052</td>\n",
       "      <td>27.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.99475</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>24.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.98923</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.037</td>\n",
       "      <td>41.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.98990</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.68</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.045</td>\n",
       "      <td>62.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.99544</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.048</td>\n",
       "      <td>36.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.039</td>\n",
       "      <td>73.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.37</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.063</td>\n",
       "      <td>48.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>35.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.99810</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.033</td>\n",
       "      <td>43.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4547 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               6.4              0.13         0.47             1.6      0.092   \n",
       "1               6.2              0.33         0.14             4.8      0.052   \n",
       "2               6.3              0.32         0.32             1.5      0.030   \n",
       "3               6.6              0.16         0.34             1.1      0.037   \n",
       "4               6.3              0.26         0.42             7.1      0.045   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4542            7.1              0.18         0.32            12.2      0.048   \n",
       "4543            7.9              0.26         0.33            10.3      0.039   \n",
       "4544            7.3              0.22         0.37            14.3      0.063   \n",
       "4545            7.2              0.51         0.24            10.0      0.093   \n",
       "4546            7.9              0.29         0.36            11.1      0.033   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    40.0                 158.0  0.99280  3.21       0.36   \n",
       "1                    27.0                 128.0  0.99475  3.21       0.48   \n",
       "2                    24.0                 101.0  0.98923  3.21       0.42   \n",
       "3                    41.0                 115.0  0.98990  3.01       0.68   \n",
       "4                    62.0                 209.0  0.99544  3.20       0.53   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4542                 36.0                 125.0  0.99670  2.92       0.54   \n",
       "4543                 73.0                 212.0  0.99690  2.93       0.49   \n",
       "4544                 48.0                 191.0  0.99780  2.89       0.38   \n",
       "4545                 35.0                 197.0  0.99810  3.41       0.47   \n",
       "4546                 43.0                 208.0  0.99690  3.14       0.46   \n",
       "\n",
       "      alcohol  color_red  color_white  quality  \n",
       "0         9.8          0            1        6  \n",
       "1         9.4          0            1        5  \n",
       "2        13.0          0            1        5  \n",
       "3        12.0          0            1        6  \n",
       "4         9.5          0            1        6  \n",
       "...       ...        ...          ...      ...  \n",
       "4542      9.4          0            1        6  \n",
       "4543      9.5          0            1        6  \n",
       "4544      9.0          0            1        6  \n",
       "4545      9.0          0            1        5  \n",
       "4546     10.3          0            1        5  \n",
       "\n",
       "[4547 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importation des données\n",
    "df_data = pd.read_csv('./data/train.csv', sep=';')\n",
    "\n",
    "df_data['color'].value_counts()\n",
    "# print(df_data)\n",
    "# One-hot encoding\n",
    "df_data = pd.get_dummies(df_data)\n",
    "column_list = ['id', 'fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
    "       'color_red', 'color_white','quality']\n",
    "\n",
    "# good_columns = ['chlorides', 'volatile acidity', 'density', 'alcohol']\n",
    "# column_names = {'0':'id', '1':'fixed acidity', '2':'volatile acidity', '3':'citric acid',\n",
    "#        '4':'residual sugar', '5':'chlorides', '6':'free sulfur dioxide',\n",
    "#        '7':'total sulfur dioxide', '8':'density', '9':'pH', '10':'sulphates', 'alcohol',\n",
    "#        'color_red', 'color_white','quality'}\n",
    "df_data = df_data[column_list]\n",
    "\n",
    "df_data = df_data[['fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
    "       'color_red', 'color_white','quality']]\n",
    "# df_data = df_data[['alcohol', 'volatile acidity', 'free sulfur dioxide',\n",
    "#                    'sulphates', 'residual sugar', 'pH', 'total sulfur dioxide', \n",
    "#                    'chlorides', 'density','quality']]\n",
    "print(df_data['quality'].value_counts())\n",
    "print(len(df_data))\n",
    "\n",
    "y = np.array(df_data['quality'])\n",
    "X = df_data.drop('quality', axis=1)\n",
    "feature_list = list(X.columns)\n",
    "X = np.array(X)\n",
    "# y = df_data.iloc[:, df_data.shape[1]-1].values\n",
    "# X = df_data.iloc[:, 0:df_data.shape[1]-1].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Hyperparameters parameters:\n",
    "P = {\n",
    "    'epochs'         : 75,        # Number of epochs\n",
    "    'batch_size'     : 100,        # Number of propagation evaluated before updating\n",
    "    'layers'         : [12, 50, 50,  1],# Input - Hidden layers - Output\n",
    "    'l_r'            : 1e-3,      # Learning rate, \n",
    "    'lambda_L2'      : 1e-4,      # L2 regularizer \n",
    "    }\n",
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_ (0.01)\n",
    "        \n",
    "        \n",
    "layers = P['layers']\n",
    "\n",
    "\n",
    "\n",
    "# We create a model on two linear hidden layers with Tanh activation function.\n",
    "# The output is a sigmoid sinice the output has to be positive (1-10).\n",
    "seq = []\n",
    "seq.append(( 'Linear0', nn.Linear(self.layers[0],self.layers[1])) )\n",
    "seq.append(( 'Tanh0', nn.Tanh()) )\n",
    "seq.append(('Linear1', nn.Linear(self.layers[1],self.layers[2])) )\n",
    "seq.append(( 'Tanh1', nn.Tanh()) )\n",
    "seq.append(('Linear2', nn.Linear(self.layers[2],self.layers[3])) )\n",
    "seq.append(( 'Sig', nn.Sigmoid())) \n",
    "# Create neural network\n",
    "\n",
    "model_seq = torch.nn.Sequential( OrderedDict(seq) )\n",
    "\n",
    "\n",
    "# we apply the initial weights, a function is define in this .py.\n",
    "model_seq.apply(init_weights)\n",
    "#######################################################\n",
    "\n",
    "# The optimizer is adam, a adaptie gradient with momentum.\n",
    "optimizer = torch.optim.Adam(model_seq.parameters(), lr=P['l_r'], weight_decay= P['lambda_L2'])\n",
    "model = model_seq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the training set in train and validation set\n",
    "\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Look at the occurence of each quality. These values will be use in the loss functions\n",
    "# to try and balance the fataset.\n",
    "Occurence = Counter(np.append(y , y_val))\n",
    "\n",
    "# Get the number of batch for one epoch\n",
    "N_batch  = np.floor(len(X)/P['batch_size']).astype(int)\n",
    "\n",
    "    \n",
    "Loss_train_epo, Loss_val_epo = [],[]\n",
    "\n",
    "X = torch.tensor(X.astype('float'), dtype = torch.float)\n",
    "X_test = torch.tensor(X_val.astype('float'), dtype = torch.float)\n",
    "for epo in range(P['epochs']):\n",
    "    \n",
    "    \n",
    "    # We randomize the index so the mini-batch will be different at each \n",
    "    # epochs\n",
    "    index_epo = np.array(range(N_batch*P['batch_size']))\n",
    "    random.shuffle(index_epo)\n",
    "    index_epo = index_epo.reshape((N_batch,P['batch_size']))\n",
    "    \n",
    "    Loss_batch = []\n",
    "    for batch in index_epo:\n",
    "        \n",
    "        # we add a 10 to keep the value in the NN lower\n",
    "        y_pred = 10*self.model(X[batch])\n",
    "        y_true = torch.tensor(y[batch], dtype = torch.float)\n",
    "        loss_prop = torch.tensor([],dtype = torch.float)\n",
    "        \n",
    "        # If the more common a quality is in a dataset, the lower the impact \n",
    "        # it will have in the loss function. We can see that the loss function is\n",
    "        # divided by  the occurence.\n",
    "        for i in  range(len(y_true)):\n",
    "            if (Occurence[y_true[i]] != 0):\n",
    "                #loss_prop = torch.cat(loss_prop, torch.square(y_pred[i] - y_true[i])/Occurence[y_true[i]])\n",
    "                loss_prop = torch.cat(loss_prop, torch.square(y_pred[i] - y_true[i]))\n",
    "            else:\n",
    "                loss_prop = torch.cat((loss_prop,torch.square( y_pred[i] - y_true[i])) )\n",
    "        \n",
    "        loss = torch.mean(loss_prop)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        Loss_batch = np.append(Loss_batch, loss.detach().numpy())\n",
    "        \n",
    "    # Validation loss\n",
    "    \n",
    "    loss_val =  torch.tensor([],dtype = torch.float)\n",
    "        \n",
    "    y_pred = 10*model(torch.tensor(X_val.astype('float'),dtype =torch.float))\n",
    "    for i in  range(len(y_val)):\n",
    "        if (Occurence[y_val[i]] != 0):\n",
    "            #loss_val = torch.cat((loss_val, torch.square((y_pred[i] - y_val[i]))/Occurence[y_val[i]])) \n",
    "            loss_val = torch.cat((loss_val, torch.square((y_pred[i] - y_val[i]))) )\n",
    "        else:\n",
    "            loss_val = torch.cat((loss_val, torch.square( y_pred[i] - y_val[i])) )\n",
    "    \n",
    "    loss_val = torch.mean(loss_val)\n",
    "    \n",
    "    Loss_train_epo = np.append(Loss_train_epo, np.mean(Loss_batch))\n",
    "    Loss_val_epo = np.append(Loss_val_epo, loss_val.detach().numpy())\n",
    "    # we print the traninig info while training\n",
    "    # print( 'Epoch: %03i,  Loss: %.2e, Loss_val: %.2e' % (epo,  loss, loss_val ))\n",
    "\n",
    "for i in range(len(X_data)):\n",
    "            if X_data[i][1]=='white':\n",
    "                X_data[i][1] = 0             \n",
    "            else:\n",
    "                X_data[i][1] = 1\n",
    "                \n",
    "# make a pandas dataframe with data    \n",
    "\n",
    "# X_data =  pd.DataFrame(np.array(X_data)[:, 1:], columns = [ 'color', 'fixed acidity', \n",
    "# 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides',\n",
    "# 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH',\n",
    "# 'sulphates', 'alcohol'] )\n",
    "\n",
    "y_pred  = 10*model(torch.tensor(np.array(X_data)[:,1:].astype('float'), dtype =torch.float))\n",
    "y_pred =  np.append(np.array(list(range(len(X_data)))),y_pred.detach().numpy().squeeze(), axis=0).reshape(2,len(y_pred)).transpose()\n",
    "\n",
    "np.round(y_pred).astype('int')\n",
    "\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "x_public = pd.read_csv('./data/test_public.csv', sep=';')\n",
    "x_public = pd.get_dummies(x_public)\n",
    "x_public = x_public[['fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
    "       'color_red', 'color_white']]\n",
    "\n",
    "label_pred = model.predict(x_public.values)\n",
    "\n",
    "label_pred = [int(a) for a in label_pred]\n",
    "id_list = np.arange((len(label_pred)))\n",
    "dict = {'id': id_list, 'quality': label_pred}\n",
    "df = pd.DataFrame(dict) \n",
    "df.to_csv('./data/submission_nn.csv', index=False)\n",
    "df.to_csv('./data/submissions/submission_nn_'+timestr+'.csv', index=False)  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4547 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6\n",
       "0     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "1     0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "2     0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "3     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "...   ...  ...  ...  ...  ...  ...  ...\n",
       "4542  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4543  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4544  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n",
       "4545  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "4546  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[4547 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dataframe = pd.read_csv('./data/train.csv', sep=';')\n",
    "\n",
    "\n",
    "# One-hot encoding\n",
    "dataframe = pd.get_dummies(dataframe)\n",
    "column_list = ['fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
    "       'quality']\n",
    "dataframe = dataframe[column_list]\n",
    "\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:11].astype(float)\n",
    "Y = dataset[:,11]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "pd.DataFrame(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-980bca5b01d3>:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (5, 6) and (5, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (5, 6) and (5, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (5, 6) and (5, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (5, 6) and (5, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (5, 6) and (5, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (None, 6) and (None, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (None, 6) and (None, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: nan% (nan%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 105, in __call__\n",
      "    score = scorer(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 418, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 313, in score\n",
      "    outputs = self.model.evaluate(x, y, **kwargs)\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1129, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1366, in test_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1356, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1349, in run_step  **\n",
      "        outputs = model.test_step(data)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1305, in test_step\n",
      "        self.compiled_loss(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1664, in categorical_crossentropy\n",
      "        return backend.categorical_crossentropy(\n",
      "    File \"C:\\Users\\j-mla\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 4994, in categorical_crossentropy\n",
      "        target.shape.assert_is_compatible_with(output.shape)\n",
      "\n",
      "    ValueError: Shapes (None, 6) and (None, 7) are incompatible\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    " \n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8, input_dim=11, activation='relu'))\n",
    "\tmodel.add(Dense(7, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction pour la soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-af1163c377a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m        'color_red', 'color_white']]\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlabel_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_public\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mlabel_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "x_public = pd.read_csv('./data/test_public.csv', sep=';')\n",
    "x_public = pd.get_dummies(x_public)\n",
    "x_public = x_public[['fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
    "       'color_red', 'color_white']]\n",
    "\n",
    "label_pred = model.predict(x_public.values)\n",
    "\n",
    "label_pred = [int(a) for a in label_pred]\n",
    "id_list = np.arange((len(label_pred)))\n",
    "dict = {'id': id_list, 'quality': label_pred}\n",
    "df = pd.DataFrame(dict) \n",
    "df.to_csv('./data/submission_nn.csv', index=False)\n",
    "df.to_csv('./data/submissions/submission_nn_'+timestr+'.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "617abead6d4232cf7e9563c8e49cb1007633705ac95bdd8e7019bb89da14d1dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
